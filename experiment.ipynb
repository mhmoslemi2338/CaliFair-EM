{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "from fairness import *\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "try: \n",
    "    with open('Data.pkl', 'rb') as f:\n",
    "        Data = pickle.load(f)\n",
    "    with open('sens_attr_dict.pkl', 'rb') as f:\n",
    "        sens_attr_dict = pickle.load(f)\n",
    "\n",
    "except:\n",
    "\n",
    "    Data = []\n",
    "    result =[]\n",
    "    for row in os.listdir('SCORES'):\n",
    "        if 'DS_Store' not in row: \n",
    "            model , dataset = row.replace('score_','').rstrip('.csv').split('_',1)\n",
    "            if model not in ['SVM', 'LogReg', 'LinReg']:\n",
    "                y_true = np.array(pd.read_csv('DATA/' + dataset + '/test.csv')['label'])\n",
    "                df = pd.read_csv('DATA/' + dataset + '/test.csv')\n",
    "                score = pd.read_csv('SCORES/'+row)\n",
    "                score = np.array(score[score.columns[0]])\n",
    "            else:\n",
    "                if dataset == 'DBLP-GoogleScholar': continue\n",
    "                df_ = pd.read_csv('SCORES/'+row)\n",
    "                y_true = np.array(df_['label']).reshape(-1)\n",
    "                score = np.array(df_['score']).reshape(-1)\n",
    "                df_ = df_[['left','right']]\n",
    "                df = df_.rename(columns={'left': 'left_'+sens_dict[dataset][0], 'right': 'right_'+sens_dict[dataset][0]})\n",
    "            result.append([score, y_true,model, dataset, df])\n",
    "\n",
    "    sens_attr_dict ={}\n",
    "\n",
    "\n",
    "\n",
    "    for i,row in enumerate(result):\n",
    "        dataset  = row[-2]\n",
    "        df = row[-1]\n",
    "        if dataset not in list(sens_attr_dict.keys()):\n",
    "            sens_attr = make_sens_vector(df , dataset, sens_dict)\n",
    "            sens_attr_dict[dataset] = sens_attr\n",
    "        else:\n",
    "            sens_attr = sens_attr_dict[dataset]\n",
    "            if sens_attr.shape[0] != score.shape[0]:\n",
    "                sens_attr = make_sens_vector(df , dataset, sens_dict)\n",
    "\n",
    "        Data.append([row[0],row[1],sens_attr,row[2],row[3]])\n",
    "        \n",
    "\n",
    "        \n",
    "    with open('sens_attr_dict.pkl', 'wb') as f:\n",
    "        pickle.dump(sens_attr_dict, f)\n",
    "    with open('Data.pkl', 'wb') as f:\n",
    "        pickle.dump(Data, f)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## introduction figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "MODEL = 'LogReg'\n",
    "DATASET = 'Amazon-Google'\n",
    "\n",
    "\n",
    "for row in Data:\n",
    "    [score, y_true,sens_attr ,model,dataset] = row\n",
    "    if dataset == DATASET and model == MODEL:\n",
    "        score_g1 = score[sens_attr ==1]\n",
    "        score_g2 = score[sens_attr ==0]\n",
    "        break\n",
    "    \n",
    "\n",
    "\n",
    "score_g1 = score[sens_attr == 1]\n",
    "score_g2 = score[sens_attr == 0]\n",
    "\n",
    "\n",
    "E_opp__sens =[]\n",
    "E_opp__non_sens = []\n",
    "E_odds_sens =[]\n",
    "E_odds__non_sens=[]\n",
    "start = 0\n",
    "end = 1\n",
    "step = 100\n",
    "range  = np.linspace(start, end, step)\n",
    "for TH in range:\n",
    "\n",
    "    y_pred = np.array([1 if score > TH else 0 for score in score])\n",
    "    additional_fairness_metrics = calculate_additional_fairness_metrics2(y_true, y_pred, sens_attr)\n",
    "    e_opp__sens = additional_fairness_metrics[0]['e_opp__sens'] \n",
    "    e_opp__non_sens = additional_fairness_metrics[0]['e_opp__non_sens'] \n",
    "    \n",
    "    e_odds_sens = additional_fairness_metrics[0]['e_odds_sens'] \n",
    "    e_odds__non_sens = additional_fairness_metrics[0]['e_odds__non_sens']\n",
    "\n",
    "    E_opp__sens.append(e_opp__sens)\n",
    "    E_opp__non_sens.append(e_opp__non_sens)\n",
    "    \n",
    "    E_odds_sens.append(e_odds_sens)\n",
    "    E_odds__non_sens.append(e_odds__non_sens)\n",
    "\n",
    "fpr1, tpr1, _ = roc_curve(y_true[sens_attr ==1],  score[sens_attr ==1],drop_intermediate=False)\n",
    "fpr2, tpr2, _ = roc_curve(y_true[sens_attr ==0],  score[sens_attr ==0],drop_intermediate=False)\n",
    "auc1 = roc_auc_score(y_true[sens_attr ==1], score[sens_attr ==1])\n",
    "auc2 = roc_auc_score(y_true[sens_attr ==0], score[sens_attr ==0])\n",
    "\n",
    "\n",
    "EO_opps_dist = calc_DP_TPR(sens_attr, y_true, score) # DP_TPR\n",
    "\n",
    "\n",
    "minority_col = \"#FF5733\"  # A shade of red\n",
    "majority_col = \"#33AFFF\"  # A shade of blue\n",
    "green_color= \"#C7E9B4\"\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "L = 1.5\n",
    "F = 28\n",
    "F_legend = 22\n",
    "F_title = 32\n",
    "size = (8,6)\n",
    "\n",
    "plt.figure(figsize=size)\n",
    "plt.plot(range,E_opp__sens,label ='Minority', color = minority_col)\n",
    "plt.plot(range,E_opp__non_sens, label ='Majority', color = majority_col)\n",
    "legend = plt.legend(fontsize = F_legend)\n",
    "legend.get_frame().set_edgecolor('black')\n",
    "plt.xlabel('Threshold (' + r'$\\tau$'+')', fontsize =F_title)  \n",
    "plt.ylabel('TPR', fontsize =F_title)  \n",
    "plt.xticks(fontsize = F)\n",
    "plt.yticks(fontsize = F)\n",
    "plt.fill_between(range, E_opp__sens, E_opp__non_sens, color='#C0C0C0', alpha=0.3)\n",
    "plt.ylim([0,1.015])\n",
    "plt.xlim([0,1])\n",
    "plt.tight_layout()\n",
    "plt.gca().get_xticklabels()[0].set_horizontalalignment('center')\n",
    "plt.gca().get_yticklabels()[0].set_verticalalignment('center')\n",
    "plt.savefig('FIGURES/introduction/Intro_EQ_OPP.pdf')\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=size)\n",
    "plt.plot(fpr1,tpr1,label ='Minority', color = minority_col, linewidth = L)\n",
    "plt.plot(fpr2,tpr2, label ='Majority', color = majority_col, linewidth = L)\n",
    "plt.plot([0, 1], [0, 1], color='black', linestyle='--')  # Adding y=x line\n",
    "legend =plt.legend(fontsize = F_legend)\n",
    "legend.get_frame().set_edgecolor('black')\n",
    "plt.xlabel('FPR', fontsize =F_title)  \n",
    "plt.ylabel('TPR', fontsize =F_title)\n",
    "plt.fill_between(fpr1, tpr1, color=minority_col, alpha=0.2)\n",
    "plt.fill_between(fpr2, tpr2, color=majority_col, alpha=0.2)\n",
    "plt.ylim([0,1.015])\n",
    "plt.xlim([-0.01,1])\n",
    "plt.xticks(fontsize = F)\n",
    "plt.yticks(fontsize = F)\n",
    "plt.gca().get_xticklabels()[0].set_horizontalalignment('center')\n",
    "plt.gca().get_yticklabels()[0].set_verticalalignment('center')\n",
    "plt.tight_layout()\n",
    "plt.savefig('FIGURES/introduction/Intro_AUC.pdf')\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before/After calibration Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 53 : HierMatcher DBLP-GoogleScholar\n",
      "2 / 53 : HierMatcher Beer\n",
      "3 / 53 : HierMatcher iTunes-Amazon\n",
      "4 / 53 : HierMatcher Beer\n",
      "5 / 53 : HierMatcher DBLP-GoogleScholar\n",
      "6 / 53 : HierMatcher Walmart-Amazon\n",
      "7 / 53 : HierMatcher Amazon-Google\n",
      "8 / 53 : HierMatcher iTunes-Amazon\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m score_g1 \u001b[38;5;241m=\u001b[39m score[sens_attr \u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      7\u001b[0m score_g2 \u001b[38;5;241m=\u001b[39m score[sens_attr \u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 10\u001b[0m bary_wass, A, bin_centers1, bin_centers2 \u001b[38;5;241m=\u001b[39m \u001b[43mcalc_bary2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\u001b[43msens_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m num  \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mmax\u001b[39m(calc_bin(score_g1), calc_bin(score_g2))), \u001b[38;5;241m400\u001b[39m)\n\u001b[1;32m     13\u001b[0m hist1, bin_edges1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhistogram(score_g1, bins\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, num\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m ))\n",
      "File \u001b[0;32m~/Desktop/Code 2/fairness.py:764\u001b[0m, in \u001b[0;36mcalc_bary2\u001b[0;34m(score, sens_attr, R)\u001b[0m\n\u001b[1;32m    760\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-4\u001b[39m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;66;03m# bary_wass = ot.unbalanced.barycenter_unbalanced(A, M, reg, alpha, weights=weights)\u001b[39;00m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;66;03m# bary_wass = ot.barycenter(A, M, reg, weights=weights, method='sinkhorn', numItermax = 10000000, stopThr= 1e-12)\u001b[39;00m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;66;03m# bary_wass = ot.bregman.barycenter(A, M, reg, weights=weights, method='sinkhorn', numItermax = 10000000, stopThr= 1e-12)\u001b[39;00m\n\u001b[0;32m--> 764\u001b[0m bary_wass\u001b[38;5;241m=\u001b[39m  \u001b[43mot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbarycenter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minterior-point\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    766\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m R:\n\u001b[1;32m    767\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bary_wass, A, bin_centers1, bin_centers2\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.12/site-packages/ot/lp/cvx.py:125\u001b[0m, in \u001b[0;36mbarycenter\u001b[0;34m(A, M, weights, verbose, log, solver)\u001b[0m\n\u001b[1;32m    122\u001b[0m     solver \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minterior-point\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    124\u001b[0m options \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisp\u001b[39m\u001b[38;5;124m'\u001b[39m: verbose, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}\n\u001b[0;32m--> 125\u001b[0m sol \u001b[38;5;241m=\u001b[39m \u001b[43msp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinprog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA_eq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mA_eq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_eq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mb_eq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m                          \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m x \u001b[38;5;241m=\u001b[39m sol\u001b[38;5;241m.\u001b[39mx\n\u001b[1;32m    128\u001b[0m b \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m-\u001b[39mn:]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.12/site-packages/scipy/optimize/_linprog.py:667\u001b[0m, in \u001b[0;36mlinprog\u001b[0;34m(c, A_ub, b_ub, A_eq, b_eq, bounds, method, callback, options, x0, integrality)\u001b[0m\n\u001b[1;32m    665\u001b[0m c0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# we might get a constant term in the objective\u001b[39;00m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m solver_options\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpresolve\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 667\u001b[0m     (lp, c0, x, undo, complete, status, message) \u001b[38;5;241m=\u001b[39m \u001b[43m_presolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m                                                             \u001b[49m\u001b[43mrr_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m                                                             \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    671\u001b[0m C, b_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# for trivial unscaling if autoscale is not used\u001b[39;00m\n\u001b[1;32m    672\u001b[0m postsolve_args \u001b[38;5;241m=\u001b[39m (lp_o\u001b[38;5;241m.\u001b[39m_replace(bounds\u001b[38;5;241m=\u001b[39mlp\u001b[38;5;241m.\u001b[39mbounds), undo, C, b_scale)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.12/site-packages/scipy/optimize/_linprog_util.py:863\u001b[0m, in \u001b[0;36m_presolve\u001b[0;34m(lp, rr, rr_method, tol)\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (sps\u001b[38;5;241m.\u001b[39missparse(A_eq)):\n\u001b[1;32m    862\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m rr \u001b[38;5;129;01mand\u001b[39;00m A_eq\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:  \u001b[38;5;66;03m# TODO: Fast sparse rank check?\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         rr_res \u001b[38;5;241m=\u001b[39m \u001b[43m_remove_redundancy_pivot_sparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA_eq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_eq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    864\u001b[0m         A_eq, b_eq, status, message \u001b[38;5;241m=\u001b[39m rr_res\n\u001b[1;32m    865\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m A_eq\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m n_rows_A:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.12/site-packages/scipy/optimize/_remove_redundancy.py:324\u001b[0m, in \u001b[0;36m_remove_redundancy_pivot_sparse\u001b[0;34m(A, rhs)\u001b[0m\n\u001b[1;32m    320\u001b[0m     e[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    322\u001b[0m pi \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39msparse\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mspsolve(B\u001b[38;5;241m.\u001b[39mtranspose(), e)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 324\u001b[0m js \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# not efficient, but this is not the time sink...\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;66;03m# Due to overhead, it tends to be faster (for problems tested) to\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;66;03m# compute the full matrix-vector product rather than individual\u001b[39;00m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;66;03m# vector-vector products (with the chance of terminating as soon\u001b[39;00m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# as any are nonzero). For very large matrices, it might be worth\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# it to compute, say, 100 or 1000 at a time and stop when a nonzero\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m# is found.\u001b[39;00m\n\u001b[1;32m    333\u001b[0m c \u001b[38;5;241m=\u001b[39m (np\u001b[38;5;241m.\u001b[39mabs(A[:, js]\u001b[38;5;241m.\u001b[39mtranspose()\u001b[38;5;241m.\u001b[39mdot(pi)) \u001b[38;5;241m>\u001b[39m tolapiv)\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "color_dict = {'minority':\"#FF5733\",\n",
    "              'majority': \"#33AFFF\",\n",
    "              'total':'#006400'}\n",
    "G_dict = {'ACC':['minority','majority'],\n",
    "          'AUC':['minority','majority'],\n",
    "          'Equalized opportunity':['majority','minority'],\n",
    "          'Equalized odds':['minority','majority'],\n",
    "          'F1-score':['minority','majority'],\n",
    "          'Positive Rate':['majority','minority'],\n",
    "          }\n",
    "\n",
    "\n",
    "cnt =0 \n",
    "\n",
    "df1 = []\n",
    "df2 = []\n",
    "df3 = []\n",
    "df4 = []\n",
    "\n",
    "for row in Data:\n",
    "    [score, y_true,sens_attr ,model,dataset] = row\n",
    "    score_g1 = score[sens_attr ==1]\n",
    "    score_g2 = score[sens_attr ==0]\n",
    "    \n",
    "\n",
    "    bary_wass, A, bin_centers1, bin_centers2 = calc_bary2(score,sens_attr, True)\n",
    "\n",
    "    num  = min(int(max(calc_bin(score_g1), calc_bin(score_g2))), 400)\n",
    "    hist1, bin_edges1 = np.histogram(score_g1, bins=np.linspace(0, 1, num+1 ))\n",
    "    hist2, bin_edges2 = np.histogram(score_g2, bins=np.linspace(0, 1, num+1 ))\n",
    "    bin_centers1_ = 0.5 * (bin_edges1[:-1] + bin_edges1[1:])\n",
    "    bin_centers2_ = 0.5 * (bin_edges2[:-1] + bin_edges2[1:])\n",
    "    hist1 = hist1 / np.sum(hist1)\n",
    "    hist2 = hist2 / np.sum(hist2)\n",
    "\n",
    "\n",
    "    mapper1 = ot.da.MappingTransport(mu=1e-3, eta=1e-20, bias=False, max_iter=2000, verbose= False, metric = 'euclidean', tol = 1e-5)\n",
    "    mapper1.fit(Xs=hist1.reshape(-1, 1),Xt = bary_wass.reshape(-1,1))\n",
    "\n",
    "    mapper2 = ot.da.MappingTransport(mu=1e-3, eta=1e-20, bias=False, max_iter=2000, verbose= False, metric = 'euclidean',tol = 1e-5)\n",
    "    mapper2.fit(Xs=hist2.reshape(-1, 1), Xt =  bary_wass.reshape(-1,1))\n",
    "\n",
    "    scores_list_1_mapped = mapper1.transform(Xs=hist1.reshape(-1, 1)).ravel()\n",
    "    scores_list_2_mapped = mapper2.transform(Xs=hist2.reshape(-1, 1)).ravel()\n",
    "\n",
    "\n",
    "    original_hist, _ = np.histogram(score_g1, bins=len(scores_list_1_mapped), range=(min(bin_edges1), max(bin_edges1)))\n",
    "    original_hist = original_hist / np.sum(original_hist)\n",
    "    target_hist = scores_list_1_mapped / np.sum(scores_list_1_mapped)\n",
    "    original_bin_midpoints = (np.linspace(min(bin_edges1), max(bin_edges1), len(original_hist))[:-1] + np.linspace(min(bin_edges1), max(bin_edges1), len(original_hist))[1:]) / 2\n",
    "    target_bin_midpoints = (bin_edges1[:-1] + bin_edges1[1:]) / 2\n",
    "    cost_matrix = ot.dist(bin_centers1[:,None], target_bin_midpoints[:, None], metric='sqeuclidean')\n",
    "    optimal_transport_plan = ot.emd(original_hist, target_hist, cost_matrix)\n",
    "    transformed_indices = np.argmax(optimal_transport_plan, axis=1)\n",
    "    transformed_data = np.interp(score_g1, bin_centers1, target_bin_midpoints[transformed_indices])\n",
    "\n",
    "\n",
    "    original_hist, _ = np.histogram(score_g2, bins=len(scores_list_2_mapped), range=(min(bin_edges1), max(bin_edges1)))\n",
    "    original_hist = original_hist / np.sum(original_hist)\n",
    "    target_hist = scores_list_2_mapped / np.sum(scores_list_2_mapped)\n",
    "    original_bin_midpoints = (np.linspace(min(bin_edges1), max(bin_edges1), len(original_hist))[:-1] + np.linspace(min(bin_edges1), max(bin_edges1), len(original_hist))[1:]) / 2\n",
    "    target_bin_midpoints = (bin_edges1[:-1] + bin_edges1[1:]) / 2\n",
    "    cost_matrix = ot.dist(bin_centers1[:,None], target_bin_midpoints[:, None], metric='sqeuclidean')\n",
    "    optimal_transport_plan = ot.emd(original_hist, target_hist, cost_matrix)\n",
    "    transformed_indices = np.argmax(optimal_transport_plan, axis=1)\n",
    "    transformed_data2 = np.interp(score_g2, bin_centers1, target_bin_midpoints[transformed_indices])\n",
    "\n",
    "    map_score = np.zeros(score.shape)\n",
    "    map_score[sens_attr == 1] = transformed_data \n",
    "    map_score[sens_attr == 0] = transformed_data2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def objective(gamma, score, y_true, sens_attr,score_repair):\n",
    "        score_best = score * (1-gamma) + gamma * score_repair\n",
    "        Eodd_disp = calc_EO_disp(sens_attr, y_true, score_best)\n",
    "        Eop_disp = calc_DP_TPR(sens_attr, y_true, score_best)\n",
    "        PR_disp = calc_DP_PR(sens_attr, y_true, score_best)\n",
    "        return Eodd_disp, Eop_disp, PR_disp\n",
    "\n",
    "\n",
    "    func_Eodd,func_PR,func_Eop = [], [] ,[]\n",
    "    for gamma in np.linspace(0, 1, 200):\n",
    "        Eodd_disp, Eop_disp, PR_disp = objective(gamma, score, y_true, sens_attr, score_repair= map_score)\n",
    "        func_Eodd.append([gamma, Eodd_disp ])\n",
    "        func_Eop.append([gamma, Eop_disp])\n",
    "        func_PR.append([gamma, PR_disp])\n",
    "        \n",
    "\n",
    "\n",
    "    func_Eop.sort(key= lambda x:x[1])\n",
    "    func_Eodd.sort(key= lambda x:x[1])\n",
    "    func_PR.sort(key= lambda x:x[1])\n",
    "\n",
    "\n",
    "\n",
    "    cnt+=1\n",
    "    print(cnt,'/',len(Data),':',MODEL+ ' '+ dataset)\n",
    "        \n",
    "\n",
    "    gamma_Eop = func_Eop[0][0]\n",
    "    gamma_Eodd = func_Eodd[0][0]\n",
    "    gamma_PR = func_PR[0][0]\n",
    "    \n",
    "    score_optimal_Eop = score * (1-gamma_Eop) + gamma_Eop * map_score\n",
    "    score_optimal_Eodd = score * (1-gamma_Eodd) + gamma_Eodd * map_score\n",
    "    score_optimal_PR = score * (1-gamma_PR) + gamma_PR * map_score\n",
    "\n",
    "    plot_bef_after(score_optimal_Eop,score_optimal_Eodd,score_optimal_PR, model,dataset,sens_attr, y_true, score)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    df1 = do_job(df1 , score_optimal_Eop,sens_attr, y_true, dataset, model, G_dict, color_dict, F, F_title, L , size , F_legend, 'final_Eop',gamma_Eop)\n",
    "    df2 = do_job(df2 , score_optimal_Eodd,sens_attr, y_true, dataset, model, G_dict, color_dict, F, F_title, L , size , F_legend, 'final_Eodd',gamma_Eodd)\n",
    "    df3 = do_job(df3 , score_optimal_PR,sens_attr, y_true, dataset, model, G_dict, color_dict, F, F_title, L , size , F_legend, 'final_PR',gamma_PR)\n",
    "\n",
    "\n",
    "\n",
    "df1.to_csv('Metric_optimal_Eop.csv',index = False)\n",
    "df2.to_csv('Metric_optimal_Eodd.csv',index = False)\n",
    "df3.to_csv('Metric_optimal_PR.csv',index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
